---
layout: post
tags: [OpenCV]
comments: true
---
<!-- TOC -->
- [前言](#前言)
- [理论部分](#理论部分)
    - [鱼眼展开流程](#鱼眼展开流程)
    - [标准坐标系与球坐标的转换](#标准坐标系与球坐标的转换)
- [代码实现](#代码实现)
    - [测试效果如下图](#测试效果如下图)
- [总结](#总结)
<!-- /TOC -->


----
 [this demo on github](https://github.com/hotsauce1861/QPano)
# 前言
鱼眼镜头相比传统的镜头，视角更广，采集的图像信息更加丰富，但是如果要对图像进行处理，就需要对其进行展开的操作，理论部分在很多论文中都已经有所提及，已经有比较成熟的方案，也不是什么比较新鲜的事情，笔者在此梳理整体的思路，总结一下所学知识，最后简单实现一下这个功能，如有错误之处，希望各位指正。

# 理论部分
鱼眼图像的展开涉及到各个坐标系的转换，其过程大致如下图所示，过程还是比较繁琐的，可以想象一下如何将地球仪展开成平面图，可能会比较容易理解一点。
![复杂的理论部分](https://img-blog.csdn.net/2018092818560433?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA2MzIxNjU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
## 鱼眼展开流程
```mermaid
flowchat
st=>start: 开始
e=>end: 结束
op=>operation: 设置输出图片尺寸
op1=>operation: 获取输出图片上的单像素点标准坐标A
op2=>operation: 将标准坐标A转换空间坐标P(x,y,z)
op3=>operation: 通过坐标P求出鱼眼标准坐标FishCoord
op4=>operation: 标准坐标FishCoord求出鱼眼图片上对应的坐标
st->op->op1->op2->op3->op4->e
```
 ## 鱼眼标准坐标计算
OpenCv读取一张鱼眼图片，其图片数据可以想象成发布在一个2D的笛卡尔坐标中的像素点的集合：$$x \in [ 0,cols-1]$$ $$y \in [ 0,cols-1]$$将输入的鱼眼图片坐标换算成标准鱼眼坐标：$$normalCoord.x = (float)((float)x * 2 / cols - 1 )$$ $$normalCoord.y = (float)((float)y * 2 / rows - 1 )$$
 鱼眼坐标系相当于球体在一个平面上的2D投影，坐标范围是[ -1, 1]，现需要将2D的坐标**A(x,y)**转化为空间坐标**P(x,y,z)**
## 标准坐标系与球坐标的转换 
球坐标的表示方式:$$P(r,\theta,\phi)   	\cdots\cdots(1)$$$$P(p,\phi,\theta)   	\cdots\cdots(2)$$
其中（1）为物理中普遍的表示方式，式（2）为数学中约定的表示方式。
**$p$ :点P与原点O连线的径向距离，下面即用OP表示；**
$\theta$ :OP与Z轴之间的夹角；
$\phi$ :OP在XOY平面的投影与正X轴的夹角；**
这里有空间坐标点$A（x,y,z）$,以下公式将球坐标系P点转换成笛卡尔坐标系：
$$x = p * sin\theta * cos\phi $$  $$y = p * sin\theta * sin \phi$$ $$z = p * cos\theta $$

以上公式在图片中未提及，这里提及以加深理解。

# 代码实现
这里主要贴一下坐标的转换代码，整个项目工程请转到 [github](https://github.com/hotsauce1861/QPano)
```cpp
FishEye& FishEye::ImgExpand2()
{
	if (mImg.empty()) {
		return *this;
	}
	printf("Current x is (%d ,%d)\n", mImg.cols, mImg.rows);

	Point2i circleCoord;
	circleCoord.x = mImg.cols / 2 + 2;
	circleCoord.y = mImg.rows / 2 + 5;
	int R = mImg.cols / 2;

	for (int i = 0; i < mDesImg.cols; i++) {
		for (int j = 0; j < mDesImg.rows; j++) {

			Point2f  pointDst = this->Shpere2Fish(i, j);
			int cols = (int)((pointDst.x + 1) * mImg.cols / 2);
			int rows = (int)((pointDst.y + 1) * mImg.rows / 2);
			printf("Current %d %d is (%d, %d) ", i, j, cols, rows);
			if (rows < mImg.rows && cols < mImg.cols
				&& rows >= 0 && cols >= 0) {
				Vec3b color_value = mImg.at<Vec3b>(rows, cols);
				mDesImg.at<Vec3b>(j, i) = color_value;
				std::cout << color_value << std::endl;
			}
		}
	}
	return *this;
}

cv::Point2f FishEye::Shpere2Fish(int x, int y)
{
	//归一化
	Point2f normalCoord;
	normalCoord.x = (float)(x * 2.0f / mFishMapImg.cols - 1);
	normalCoord.y = (float)(y * 2.0f / mFishMapImg.rows - 1);

	float longitude = (float)(normalCoord.x * PI);
	float latitude = (float)(normalCoord.y * PI/2);

	Point3f coordP;
	coordP.x = cos(latitude)*cos(longitude);
	coordP.y = cos(latitude)*sin(longitude);
	coordP.z = sin(latitude);
	float r = 2 * atan2(sqrt(coordP.x*coordP.x + coordP.z*coordP.z), coordP.y) / MFOV;
	float theta = atan2(coordP.z, coordP.x);

	Point2f fishCoord;
	fishCoord.x = r * cos(theta);
	fishCoord.y = r * sin(theta);

	return fishCoord;
}
```
## 测试效果如下图
![在这里插入图片描述](https://img-blog.csdn.net/20181011154934311?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA2MzIxNjU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
# 总结
整个过程中，遇到过一个较大的问题，之前一直难以理解。如果先输入一张鱼眼图像，通过鱼眼图像的坐标映射到展开图片，会出现很多像素点缺失的情况，可以测试一下，仓库对应的方法为**ImgExpand()**。在ImgExpand2中解决了这个问题，是从输出图片的坐标去推算并寻找鱼眼图片上相应的像素点，同样的，还有一些参数需要提取进行接口化的设计。比如**提取鱼眼图像的有效区域**，**有效区域半径的计算**，**读取exif获取镜头视角或者预留接口**，**展开图片后的抗锯齿化处理**等等，还需要完善，另外有什么问题，望不吝赐教。
